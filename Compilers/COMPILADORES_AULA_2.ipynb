{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwxHf3E81Qyz"
   },
   "source": [
    "**COMPILADORES - AULA 2**\n",
    "\n",
    "***Prof. Luciano Silva***\n",
    "\n",
    "**Objetivos da aula:**\n",
    "*   revisar implementação de analisadores léxicos em rply\n",
    "*   analisar a grmática da linguagem TINY-C\n",
    "*   implementar um analisador léxico para TINY-C\n",
    "*   aumentar a gramática da TINY-C e imlementar um analisador léxico para isto\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGMxqj9y7vWS"
   },
   "source": [
    "**REVISÃO - AULA ANTERIOR**\n",
    "\n",
    "Queremos constuir um analisador léxico para os símbolos terminais da gramática abaixo:\n",
    "\n",
    "\\<expression\\> ::= NUMBER\n",
    "\n",
    "               | \\<expression\\> \"+\" \\<expression\\>\n",
    "\n",
    "               | \\<expression\\> \"-\" \\<expression\\>\n",
    "\n",
    "               | \\<expression\\> \"*\" \\<expression\\>\n",
    "\n",
    "               | \\<expression\\> \"/\" \\<expression\\>\n",
    "\n",
    "               | \"(\" <expression> \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdlT1XbX8PFb"
   },
   "source": [
    "O primeiro passo é instalar o rply, um módulo para construir analisadores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CbWUx55j1tLM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rply in c:\\users\\uemaj\\anaconda3\\lib\\site-packages (0.7.8)\n",
      "Requirement already satisfied: appdirs in c:\\users\\uemaj\\anaconda3\\lib\\site-packages (from rply) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install rply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQEvnI9-9S-n"
   },
   "source": [
    "Toda a documentação do rply pode ser encontrada abaixo:\n",
    "\n",
    "<a href=\"https://rply.readthedocs.io/en/latest/\">Documentação RPLY </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdp5ClkZ98Tw"
   },
   "source": [
    "O segundo passo é construir o analisador léxico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rezf3OAt1P7_"
   },
   "outputs": [],
   "source": [
    "from rply import LexerGenerator\n",
    "\n",
    "lg = LexerGenerator()\n",
    "\n",
    "lg.add('NUMBER', r'\\d+')\n",
    "lg.add('PLUS', r'\\+')\n",
    "lg.add('MINUS', r'-')\n",
    "lg.add('MUL', r'\\*')\n",
    "lg.add('DIV', r'/')\n",
    "lg.add('OPEN_PARENS', r'\\(')\n",
    "lg.add('CLOSE_PARENS', r'\\)')\n",
    "\n",
    "lg.ignore('\\s+')\n",
    "\n",
    "lexer = lg.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gxpqmaf9khR"
   },
   "source": [
    "Observe que, associado a cada classe léxica, temos uma expressão regular associada. Esta expressão regular usa a facilidade RegEx do Python, cuja documentação pode ser enontrada abaixo:\n",
    "\n",
    "<a href=\"https://blog.geekhunter.com.br/python-regex/\"> Expressões Regulares em Python </a>\n",
    "\n",
    "Para usar somente o analisador léxico, podemos usar o código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8CrRKNZi9vMr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token('NUMBER', '1')\n",
      "Token('PLUS', '+')\n",
      "Token('NUMBER', '1')\n",
      "Token('MINUS', '-')\n",
      "Token('NUMBER', '1')\n"
     ]
    }
   ],
   "source": [
    "for token in lexer.lex('1+1-1'):\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbZuGJ8r2dSg"
   },
   "source": [
    "**LINGUAGEM TINY-C**\n",
    "\n",
    "Abaixo temos a gramática (livre de contexto) da linguagem TINY-C, um subconjunto bastante expressivo da linguagem C:\n",
    "\n",
    "<i>\n",
    "Smallc_program ::= type_specifier id ‘(‘ param_decl_list ‘)’ compound_stmt\n",
    "\n",
    "Type_specifier ::= int | char\n",
    "\n",
    "Param_decl_list ::= parameter_decl (‘,’ parameter_decl )*\n",
    "\n",
    "Param_decl ::= type_specifier id\n",
    "\n",
    "Compound_stmt ::= ‘{‘ (var_decl* stmt*)? ‘}’\n",
    "\n",
    "Var_decl ::= type_specifier var_decl_list ‘;’ \n",
    "\n",
    "Var_decl_list ::= variable_id ( ‘,’ variable_id)*\n",
    "\n",
    "Variable_id ::= id ( ‘=’ expr )?\n",
    "\n",
    "Stmt ::= compound_stmt | cond_stmt | while_stmt | break ‘;’ | continue ‘;’ | return expr ‘;’ | readint ‘(‘ id ‘)’ ‘;’ |\n",
    " writeint ‘(‘ expr ‘)’ ‘;’\n",
    "\n",
    "Cond_stmt ::= if ‘(‘ expr ‘)’ stmt (else stmt)?\n",
    "\n",
    "While_stmt ::= while ‘(‘ expr ‘)’ stmt\n",
    "\n",
    "Expr ::= id ‘=’ expr | condition\n",
    "\n",
    "Condition ::= disjunction | disjunction ‘?’ expr ‘:’ condition\n",
    "\n",
    "Disjunction ::= conjunction | disjunction ‘||’ conjunction\n",
    "\n",
    "Conjunction ::= comparison | conjunction ‘&&’ comparison\n",
    "\n",
    "Comparison ::= relation | relation ‘==’ relation\n",
    "\n",
    "Relation ::= sum | sum (‘<’ | ‘>’) sum\n",
    "\n",
    "Sum ::= sum ‘+’ term | sum ‘-’ term | term\n",
    "\n",
    "Term ::= term ‘*’ factor | term ‘/’ factor | term ‘%’ factor | factor\n",
    "\n",
    "Factor ::= ‘!’ factor | ‘-’ factor | primary\n",
    "\n",
    "Primary ::= num | charconst | id | ‘(‘ expr ‘)’\n",
    "</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPM4_Jpf3SGP"
   },
   "source": [
    "**EXERCÍCIO PROPOSTO**\n",
    "\n",
    "Escreva um programa na linguagem TINY-C:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHTZVpl63tla"
   },
   "source": [
    "```c\n",
    "int printaletras(char letra, int qtde){\n",
    "    char a = letra;\n",
    "    int b = qtde;\n",
    "    \n",
    "    int i = 0;\n",
    "\n",
    "    while (i < qtde){\n",
    "        writeChar(a);\n",
    "        i = i + 1;\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sProgramaC = '''\n",
    "int printaletras(char letra, int qtde){\n",
    "    char a = letra;\n",
    "    int b = qtde;\n",
    "    \n",
    "    int i = 0;\n",
    "\n",
    "    while (i < qtde){\n",
    "        writeChar(a);\n",
    "        i = i + 1;\n",
    "}\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6URuPQaL4D8j"
   },
   "source": [
    "**EXERCÍCIO PROPOSTO**\n",
    "\n",
    "Escreva um analisador léxico para a gramática acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vHY05GN54P9t"
   },
   "outputs": [],
   "source": [
    "# Tokens são tudo o que aparece do lado direito (→) mas não do lado esquerdo (←)\n",
    "\n",
    "lg = LexerGenerator()\n",
    "\n",
    "# Regra Type_specifier ::= int | char\n",
    "lg.add('INT', r'int')\n",
    "lg.add('CHAR', r'char')\n",
    "\n",
    "# Regra Stmt ::= compound_stmt | cond_stmt | while_stmt | break ‘;’ |\n",
    "#                continue ‘;’ | return expr ‘;’ | readint ‘(‘ id ‘)’ ‘;’ |\n",
    "#                writeint ‘(‘ expr ‘)’ ‘;’\n",
    "lg.add('BREAK', r'break')\n",
    "lg.add('CONTINUE', r'continue')\n",
    "lg.add('READINT', r'readint')\n",
    "lg.add('READCHAR', r'readChar')\n",
    "lg.add('WRITEINT', r'writeint')\n",
    "lg.add('WRITECHAR', r'writeChar')\n",
    "lg.add('RETURN', r'return')\n",
    "\n",
    "# Regra Smallc_program ::= type_specifier id ‘(‘ param_decl_list ‘)’ compound_stmt\n",
    "lg.add('ID', r'[a-zA-Z][a-zA-Z0-9]*')\n",
    "lg.add('OPEN_PARENS', r'\\(')\n",
    "lg.add('CLOSE_PARENS', r'\\)')\n",
    "\n",
    "# Regra Param_decl_list ::= parameter_decl (‘,’ parameter_decl )*\n",
    "lg.add('COMMA', r',')\n",
    "\n",
    "# Regra Param_decl ::= type_specifier id\n",
    "## Tokens já adicionados\n",
    "\n",
    "# Regra Compound_stmt ::= ‘{‘ (var_decl* stmt*)? ‘}’\n",
    "lg.add('OPEN_BRACES', r'\\{')\n",
    "lg.add('CLOSE_BRACES', r'\\}')\n",
    "\n",
    "# Regra Var_decl ::= type_specifier var_decl_list ‘;’\n",
    "lg.add('SEMICOLON',r';')\n",
    "\n",
    "# Regra Var_decl_list ::= variable_id ( ‘,’ variable_id)*\n",
    "## Tokens já adicionados\n",
    "\n",
    "# Regra Variable_id ::= id ( ‘=’ expr )?\n",
    "lg.add('EQUALS',r'=')\n",
    "\n",
    "# Regra Cond_stmt ::= if ‘(‘ expr ‘)’ stmt (else stmt)?\n",
    "lg.add('IF', r'if')\n",
    "lg.add('ELSE', r'else')\n",
    "\n",
    "# Regra While_stmt ::= while ‘(‘ expr ‘)’ stmt\n",
    "lg.add('WHILE', r'while')\n",
    "\n",
    "# Regra Expr ::= id ‘=’ expr | condition\n",
    "lg.add('EQUALS',r'=')\n",
    "\n",
    "# Regra Condition ::= disjunction | disjunction ‘?’ expr ‘:’ condition\n",
    "lg.add('QUESTION_MARK', r'\\?')\n",
    "lg.add('COLON', r':')\n",
    "\n",
    "# Regra Disjunction ::= conjunction | disjunction ‘||’ conjunction\n",
    "lg.add('OR', r'\\|\\|')\n",
    "\n",
    "# Regra Conjunction ::= comparison | conjunction ‘&&’ comparison\n",
    "lg.add('AND', r'&&')\n",
    "\n",
    "# Regra Comparison ::= relation | relation ‘==’ relation\n",
    "lg.add('DOUBLE_EQUAL', r'==')\n",
    "\n",
    "# Regra Relation ::= sum | sum (‘<’ | ‘>’) sum\n",
    "lg.add('GREATER', r'\\<')\n",
    "lg.add('LOWER', r'\\>')\n",
    "\n",
    "# Regra Sum ::= sum ‘+’ term | sum ‘-’ term | term\n",
    "lg.add('PLUS', r'\\+')\n",
    "lg.add('MINUS', r'-')\n",
    "\n",
    "# Regra Term ::= term ‘*’ factor | term ‘/’ factor | term ‘%’ factor | factor\n",
    "lg.add('MUL', r'\\*')\n",
    "lg.add('DIV', r'/')\n",
    "lg.add('MOD', r'%')\n",
    "\n",
    "# Regra Factor ::= ‘!’ factor | ‘-’ factor | primary\n",
    "lg.add('NOT', r'!')\n",
    "\n",
    "# Regra Primary ::= num | charconst | id | ‘(‘ expr ‘)’\n",
    "lg.add('NUMBER', r'\\d+')\n",
    "lg.add('CHAR', r'\\w+')\n",
    "\n",
    "lg.ignore('\\s+')\n",
    "\n",
    "lexer = lg.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QeqnWD94j2E"
   },
   "source": [
    "**EXERCÍCIO PROPOSTO**\n",
    "\n",
    "Aplique seu analisador léxico para quebrar em tokens o seu programa escrito em TINY-C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HmQxwqVA4wgf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token('INT', 'int')\n",
      "Token('ID', 'printaletras')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('CHAR', 'char')\n",
      "Token('ID', 'letra')\n",
      "Token('COMMA', ',')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'qtde')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('OPEN_BRACKETS', '{')\n",
      "Token('CHAR', 'char')\n",
      "Token('ID', 'a')\n",
      "Token('EQUALS', '=')\n",
      "Token('ID', 'letra')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'b')\n",
      "Token('EQUALS', '=')\n",
      "Token('ID', 'qtde')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'i')\n",
      "Token('EQUALS', '=')\n",
      "Token('NUMBER', '0')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('ID', 'while')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'i')\n",
      "Token('GREATER', '<')\n",
      "Token('ID', 'qtde')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('OPEN_BRACKETS', '{')\n",
      "Token('WRITECHAR', 'writeChar')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'a')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('ID', 'i')\n",
      "Token('EQUALS', '=')\n",
      "Token('ID', 'i')\n",
      "Token('PLUS', '+')\n",
      "Token('NUMBER', '1')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CLOSE_BRACKETS', '}')\n",
      "Token('RETURN', 'return')\n",
      "Token('NUMBER', '0')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CLOSE_BRACKETS', '}')\n"
     ]
    }
   ],
   "source": [
    "for token in lexer.lex(sProgramaC):\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as3YFA_m-KTm"
   },
   "source": [
    "**ATIVIDADE EAD**\n",
    "\n",
    "\n",
    "1.   Aumentar as regras de sua gramática para incluir mais de uma função por programa\n",
    "2.   Aumentar as regras de sua gramática para incluir definição de vetores no estilo C  (Exemplo: int v[10];)\n",
    "3.   Implementar um analisador léxico para incluir as duas novas regras acima\n",
    "4.   Escrever um programa em TINY-C (com as novas regras acima) e fazer sua análise léxica com  o analisador do item (3).\n",
    "\n",
    "**O que entregar:** notebook contendo os programas em Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LexerGenerator()\n",
    "\n",
    "## Regras do novo Analisador\n",
    "\n",
    "# Regra Type_specifier ::= int | char\n",
    "lg.add('INT', r'int')\n",
    "lg.add('CHAR', r'char')\n",
    "\n",
    "# Regra Stmt ::= compound_stmt | cond_stmt | while_stmt | break ‘;’ |\n",
    "#                continue ‘;’ | return expr ‘;’ | readint ‘(‘ id ‘)’ ‘;’ |\n",
    "#                writeint ‘(‘ expr ‘)’ ‘;’\n",
    "lg.add('BREAK', r'break')\n",
    "lg.add('CONTINUE', r'continue')\n",
    "lg.add('READINT', r'readint')\n",
    "lg.add('READCHAR', r'readChar')\n",
    "lg.add('WRITEINT', r'writeint')\n",
    "lg.add('WRITECHAR', r'writeChar')\n",
    "lg.add('RETURN', r'return')\n",
    "\n",
    "# Regra Smallc_program ::= type_specifier id ‘(‘ param_decl_list ‘)’ compound_stmt\n",
    "lg.add('ID', r'[a-zA-Z][a-zA-Z0-9_]*')\n",
    "lg.add('OPEN_PARENS', r'\\(')\n",
    "lg.add('CLOSE_PARENS', r'\\)')\n",
    "\n",
    "# Regra Param_decl_list ::= parameter_decl (‘,’ parameter_decl )*\n",
    "lg.add('COMMA', r',')\n",
    "\n",
    "# Regra Param_decl ::= type_specifier id\n",
    "## Tokens já adicionados\n",
    "\n",
    "# Regra Compound_stmt ::= ‘{‘ (var_decl* stmt*)? ‘}’\n",
    "lg.add('OPEN_BRACES', r'\\{')\n",
    "lg.add('CLOSE_BRACES', r'\\}')\n",
    "\n",
    "# Regra Vector ::= type_specifier id | id ‘=’ id ‘[’ (expr | num)? ‘]’  ←←←←← Nova Regra\n",
    "lg.add('OPEN_BRACKETS', r'\\[')\n",
    "lg.add('CLOSE_BRACKETS', r'\\]')\n",
    "\n",
    "# Regra Var_decl ::= type_specifier var_decl_list ‘;’\n",
    "lg.add('SEMICOLON',r';')\n",
    "\n",
    "# Regra Var_decl_list ::= variable_id ( ‘,’ variable_id)*\n",
    "## Tokens já adicionados\n",
    "\n",
    "# Regra Variable_id ::= id ( ‘=’ expr )?\n",
    "lg.add('EQUALS',r'=')\n",
    "\n",
    "# Regra Cond_stmt ::= if ‘(‘ expr ‘)’ stmt (else stmt)?\n",
    "lg.add('IF', r'if')\n",
    "lg.add('ELSE', r'else')\n",
    "\n",
    "# Regra While_stmt ::= while ‘(‘ expr ‘)’ stmt\n",
    "lg.add('WHILE', r'while')\n",
    "\n",
    "# Regra Expr ::= id ‘=’ expr | condition\n",
    "lg.add('EQUALS',r'=')\n",
    "\n",
    "# Regra Condition ::= disjunction | disjunction ‘?’ expr ‘:’ condition\n",
    "lg.add('QUESTION_MARK', r'\\?')\n",
    "lg.add('COLON', r':')\n",
    "\n",
    "# Regra Disjunction ::= conjunction | disjunction ‘||’ conjunction\n",
    "lg.add('OR', r'\\|\\|')\n",
    "\n",
    "# Regra Conjunction ::= comparison | conjunction ‘&&’ comparison\n",
    "lg.add('AND', r'&&')\n",
    "\n",
    "# Regra Comparison ::= relation | relation ‘==’ relation\n",
    "lg.add('DOUBLE_EQUAL', r'==')\n",
    "\n",
    "# Regra Relation ::= sum | sum (‘<’ | ‘>’) sum\n",
    "lg.add('GREATER', r'\\<')\n",
    "lg.add('LOWER', r'\\>')\n",
    "\n",
    "# Regra Sum ::= sum ‘+’ term | sum ‘-’ term | term\n",
    "lg.add('PLUS', r'\\+')\n",
    "lg.add('MINUS', r'-')\n",
    "\n",
    "# Regra Term ::= term ‘*’ factor | term ‘/’ factor | term ‘%’ factor | factor\n",
    "lg.add('MUL', r'\\*')\n",
    "lg.add('DIV', r'/')\n",
    "lg.add('MOD', r'%')\n",
    "\n",
    "# Regra Factor ::= ‘!’ factor | ‘-’ factor | primary\n",
    "lg.add('NOT', r'!')\n",
    "\n",
    "# Regra Primary ::= num | charconst | id | ‘(‘ expr ‘)’\n",
    "lg.add('NUMBER', r'\\d+')\n",
    "lg.add('CHAR', r'\\w+')\n",
    "\n",
    "lg.ignore('\\s+')\n",
    "\n",
    "lexer = lg.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sNewTinyC = '''\n",
    "char le_palavra(char palavra[], int tamanho){\n",
    "\n",
    "    int i = 0;\n",
    "\n",
    "    while(i < tamanho){\n",
    "        readChar(palavra[i]);\n",
    "        i = i + 1;\n",
    "    }\n",
    "\n",
    "    return palavra;\n",
    "}\n",
    "\n",
    "int printa_palavra(char palavra[], int tamanho){\n",
    "\n",
    "    int i = 0;\n",
    "\n",
    "    while(i < tamanho){\n",
    "        writeChar(palavra[i]);\n",
    "        i = i + 1;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "int main(){\n",
    "\n",
    "    int tam;\n",
    "    readint(tam);\n",
    "    char palavra[tam];\n",
    "    \n",
    "    palavra = le_palavra(palavra, tam);\n",
    "\n",
    "    return printa_palavra(palavra, tam);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token('CHAR', 'char')\n",
      "Token('ID', 'le_palavra')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('CHAR', 'char')\n",
      "Token('ID', 'palavra')\n",
      "Token('OPEN_BRACKETS', '[')\n",
      "Token('CLOSE_BRACKETS', ']')\n",
      "Token('COMMA', ',')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'tamanho')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('OPEN_BRACES', '{')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'i')\n",
      "Token('EQUALS', '=')\n",
      "Token('NUMBER', '0')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('ID', 'while')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'i')\n",
      "Token('GREATER', '<')\n",
      "Token('ID', 'tamanho')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('OPEN_BRACES', '{')\n",
      "Token('READCHAR', 'readChar')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'palavra')\n",
      "Token('OPEN_BRACKETS', '[')\n",
      "Token('ID', 'i')\n",
      "Token('CLOSE_BRACKETS', ']')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('ID', 'i')\n",
      "Token('EQUALS', '=')\n",
      "Token('ID', 'i')\n",
      "Token('PLUS', '+')\n",
      "Token('NUMBER', '1')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CLOSE_BRACES', '}')\n",
      "Token('RETURN', 'return')\n",
      "Token('ID', 'palavra')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CLOSE_BRACES', '}')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'printa_palavra')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('CHAR', 'char')\n",
      "Token('ID', 'palavra')\n",
      "Token('OPEN_BRACKETS', '[')\n",
      "Token('CLOSE_BRACKETS', ']')\n",
      "Token('COMMA', ',')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'tamanho')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('OPEN_BRACES', '{')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'i')\n",
      "Token('EQUALS', '=')\n",
      "Token('NUMBER', '0')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('ID', 'while')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'i')\n",
      "Token('GREATER', '<')\n",
      "Token('ID', 'tamanho')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('OPEN_BRACES', '{')\n",
      "Token('WRITECHAR', 'writeChar')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'palavra')\n",
      "Token('OPEN_BRACKETS', '[')\n",
      "Token('ID', 'i')\n",
      "Token('CLOSE_BRACKETS', ']')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('ID', 'i')\n",
      "Token('EQUALS', '=')\n",
      "Token('ID', 'i')\n",
      "Token('PLUS', '+')\n",
      "Token('NUMBER', '1')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CLOSE_BRACES', '}')\n",
      "Token('RETURN', 'return')\n",
      "Token('NUMBER', '0')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CLOSE_BRACES', '}')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'main')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('OPEN_BRACES', '{')\n",
      "Token('INT', 'int')\n",
      "Token('ID', 'tam')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('READINT', 'readint')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'tam')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CHAR', 'char')\n",
      "Token('ID', 'palavra')\n",
      "Token('OPEN_BRACKETS', '[')\n",
      "Token('ID', 'tam')\n",
      "Token('CLOSE_BRACKETS', ']')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('ID', 'palavra')\n",
      "Token('EQUALS', '=')\n",
      "Token('ID', 'le_palavra')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'palavra')\n",
      "Token('COMMA', ',')\n",
      "Token('ID', 'tam')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('RETURN', 'return')\n",
      "Token('ID', 'printa_palavra')\n",
      "Token('OPEN_PARENS', '(')\n",
      "Token('ID', 'palavra')\n",
      "Token('COMMA', ',')\n",
      "Token('ID', 'tam')\n",
      "Token('CLOSE_PARENS', ')')\n",
      "Token('SEMICOLON', ';')\n",
      "Token('CLOSE_BRACES', '}')\n"
     ]
    }
   ],
   "source": [
    "for token in lexer.lex(sNewTinyC):\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COMPILADORES-AULA 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
